{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNÇÕES DE AJUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificar Var Numéricas e Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_types(df, target_col='Tipo de Ataque'):\n",
    "    '''\n",
    "    Identifica Categorias Numéricas e Categóricas\n",
    "    '''\n",
    "    numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_features = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "    # Remove Variável Alvo\n",
    "    if target_col in numeric_features:\n",
    "        numeric_features.remove(target_col)\n",
    "    if target_col in categorical_features:\n",
    "        categorical_features.remove(target_col)\n",
    "\n",
    "    return numeric_features, categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizar Correlação Entre Features Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_analysis(df, numeric_features, threshold=0.85):\n",
    "    '''\n",
    "    Analiza Correlação entre Features Numéricas\n",
    "\n",
    "    Threshold 0.85 para procurar correlações fortes\n",
    "    '''\n",
    "\n",
    "    corr_matrix = df[numeric_features].corr()\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, linewidth= 0.5)\n",
    "\n",
    "    plt.title('Correlação entre Features - Heatmap')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()\n",
    "\n",
    "    threshold = threshold\n",
    "    high_corr = np.where(np.abs(corr_matrix) > threshold)\n",
    "    high_corr = [(corr_matrix.index[x], corr_matrix.columns[y], corr_matrix.iloc[x, y]) for x, y in zip(*high_corr) if x != y and x < y]\n",
    "    \n",
    "    return high_corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Homogeneidade da Variância (Teste de Levene's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_variance_homogen(df, numeric_features, target_col='Tipo de Ataque'):\n",
    "    '''\n",
    "    Análise de Variância Homogénea\n",
    "    '''\n",
    "\n",
    "    results_levene = {}\n",
    "\n",
    "    for feature in numeric_features:\n",
    "        groups = [group[feature].dropna().values for name, group in df.groupby(target_col) if not group[feature].dropna().empty] \n",
    "\n",
    "        groups = [group for group in groups if len(group) > 0 and np.any(group != 0) and np.var(group) > 0]\n",
    "\n",
    "        if len(groups) < 2:\n",
    "            print(f\"Não existem grupos válidos para fazer o teste de Levene para a feature: {feature}\")\n",
    "            continue\n",
    "\n",
    "        stat_levene, p_value_levene = stats.levene(*groups)  \n",
    "        results_levene[feature] = {'Statistic': stat_levene, 'p-value': p_value_levene}  \n",
    "\n",
    "    return results_levene\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise da Importância das Features com Teste Kurskal-Wallis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(df, numeric_features, target_col='Tipo de Ataque'):\n",
    "    '''\n",
    "    Análise de Importância de Features\n",
    "    '''\n",
    "\n",
    "    h_scores = {}\n",
    "\n",
    "    for feature in numeric_features:\n",
    "        groups = [group[feature].dropna().values for name, group in df.groupby(target_col)]\n",
    "        h_stat, p_value = stats.kruskal(*groups)\n",
    "        h_scores[feature] = {'H-Statistic': h_stat, 'p-value': p_value}\n",
    "\n",
    "    h_scores_df = pd.DataFrame.from_dict(h_scores, orient='index')\n",
    "    h_scores_df = h_scores_df.sort_values('H-Statistic', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    plt.bar(range(len(h_scores_df)), h_scores_df['H-Statistic'], color='skyblue')\n",
    "    plt.xticks(range(len(h_scores_df)), h_scores_df.index, rotation=90)\n",
    "    plt.title('Importância de Features - Teste de Kruskal-Wallis')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('H-Statistic')\n",
    "    plt.show()\n",
    "\n",
    "    return h_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise da Importância das Features com Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance_rf(df, numeric_features, target_col='Tipo de Ataque'):\n",
    "    '''\n",
    "    Análise de Importância de Features com Random Forest\n",
    "    '''\n",
    "\n",
    "    hyper_params = {\n",
    "        'n_estimators': 150, # Número de Árvores\n",
    "        'max_depth': 5, # Limite da Profundidade das Árvores\n",
    "        'random_state': 42, # Para Reprodutibilidade\n",
    "        'n_jobs': -1 # Para Paralelização\n",
    "    }\n",
    "\n",
    "    X = df[numeric_features]\n",
    "    y = df[target_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=hyper_params['random_state'], stratify=y)\n",
    "\n",
    "    rf = RandomForestClassifier(**hyper_params)\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    cv_scores = cross_val_score(rf, X_train, y_train, cv=5, n_jobs=-1)\n",
    "    print(f\"Cross-Validation Scores: {np.mean(cv_scores):.4f} +/- {np.std(cv_scores):.4f}\")\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    importances = rf.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({'Feature': numeric_features, 'Importance': importances})\n",
    "    feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "    rf_labels = rf.classes_\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, target_names=rf_labels)\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(report, end='\\n\\n')\n",
    "\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    plt.bar(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "    plt.ylabel('Importância')\n",
    "    plt.xlabel('Features')\n",
    "    plt.title('Importância de Features - Random Forest')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return feature_importance_df, cm, rf_labels, cv_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo da Percentagem de Outliers para Cada Feature com IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_outliers_percentage(df):\n",
    "    '''\n",
    "    Calcula a Percentagem de Outliers com Método IQR\n",
    "    '''\n",
    "\n",
    "    outliers_percentage = {}\n",
    "\n",
    "    for column in df.columns:\n",
    "        q1 = df[column].quantile(0.25)\n",
    "        q3 = df[column].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "\n",
    "        outliers_percentage[column] = len(outliers) / len(df) * 100\n",
    "\n",
    "        outliers_percentage[column] = outliers_percentage\n",
    "   \n",
    "    return outliers_percentage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
